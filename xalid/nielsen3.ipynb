{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import PandasHelper as pdh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_PATH = 'data/'\n",
    "MAIN_FILE = DATA_PATH+'nielsen.csv'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df =pd.read_csv(MAIN_FILE,nrows=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site_name</th>\n",
       "      <th>first_timeframe</th>\n",
       "      <th>dwell_time_s</th>\n",
       "      <th>device_id</th>\n",
       "      <th>visitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BF Karlsruhe Kaiserstr (1122)</td>\n",
       "      <td>2014-12-31 23:00:30+00:00</td>\n",
       "      <td>15</td>\n",
       "      <td>bd5d8c2890622782d681c82f4dd84db4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BF Karlsruhe Kaiserstr (1122)</td>\n",
       "      <td>2014-12-31 23:00:40+00:00</td>\n",
       "      <td>1080</td>\n",
       "      <td>428fa91d6d741e1466b4bcd917dff4c2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       site_name            first_timeframe  dwell_time_s  \\\n",
       "0  BF Karlsruhe Kaiserstr (1122)  2014-12-31 23:00:30+00:00            15   \n",
       "1  BF Karlsruhe Kaiserstr (1122)  2014-12-31 23:00:40+00:00          1080   \n",
       "\n",
       "                          device_id visitor  \n",
       "0  bd5d8c2890622782d681c82f4dd84db4    True  \n",
       "1  428fa91d6d741e1466b4bcd917dff4c2    True  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-Create indexes table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def chunk_and_retrieve_indexes():\n",
    "    chunks = pd.read_csv(MAIN_FILE,chunksize=1000000)\n",
    "    \n",
    "    for i,chunk in enumerate(chunks):\n",
    "        print chunk.shape\n",
    "        devices_ix = pd.DataFrame(chunk.device_id.unique())\n",
    "        sites_ix = pd.DataFrame(chunk.site_name.unique())\n",
    "        devices_ix.to_csv(DATA_PATH+\"indexes/devices/devices_ix_\"+str(i)+\".csv\")\n",
    "        sites_ix.to_csv(DATA_PATH+\"indexes/sites/sites_ix_.csv\"+str(i)+\".csv\")\n",
    "\n",
    "def concatenate_df(df,path):\n",
    "    df1 = pd.read_csv(path,index_col=0)\n",
    "   \n",
    "    return pd.concat([df,df1]).drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "def concatenate_index_files():\n",
    "    index_devices_files = pdh.get_files(DATA_PATH+\"indexes/devices/\")\n",
    "    index_sites_files = pdh.get_files(DATA_PATH+\"indexes/sites/\")\n",
    "    \n",
    "    df_devices_ix = pd.DataFrame()\n",
    "    df_sites_ix = pd.DataFrame()\n",
    "    \n",
    "    for index_device_file in index_devices_files:\n",
    "        print index_device_file\n",
    "        df_devices_ix = concatenate_df(df_devices_ix,DATA_PATH+\"indexes/devices/\"+index_device_file)\n",
    "    df_devices_ix.columns=['id','device_mac']\n",
    "    df_devices_ix.to_csv(DATA_PATH+\"indexes/devices_ix.csv\")\n",
    "    \n",
    "    for index_sites_file in index_sites_files:\n",
    "        df_sites_ix = concatenate_df(df_sites_ix,DATA_PATH+\"indexes/sites/\"+index_sites_file)\n",
    "    df_sites_ix.columns=['id','site_name']\n",
    "    df_sites_ix.to_csv(DATA_PATH+\"indexes/sites_ix.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-replace devices and sites name with ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def merge_agg_with_device_and_sites_index():\n",
    "    chunks=pd.read_csv(DATA_PATH+\"nielsen.csv\",chunksize=1000000)\n",
    "    df_devices_idx = pd.read_csv(DATA_PATH+\"indexes/devices_ix.csv\")\n",
    "    df_sites_index = pd.read_csv(DATA_PATH+\"indexes/sites_ix.csv\")\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    for i,chunk in enumerate(chunks):\n",
    "        print chunk.shape, i\n",
    "        chunk = pd.merge(chunk, df_devices_idx, left_on='device_id', right_on='device_mac',suffixes=('_agg', '_devicesidx'))\n",
    "        chunk = chunk[['id','site_name','first_timeframe']]\n",
    "        chunk = pd.merge(chunk, df_sites_index, on='site_name', suffixes=('_devices','_sites'))\n",
    "        chunk=chunk[['id_devices', 'id_sites']]\n",
    "        chunk=chunk.astype('int32')\n",
    "        df = pd.concat([df,chunk], axis=0, ignore_index=True)\n",
    "    print \"merge over,starting saving to disk...\"\n",
    "    df.to_csv(DATA_PATH+'/nielsen_indexes.csv')\n",
    "    print \"saved to disk OK.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3-Aggregate per devices and site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(DATA_PATH+'/nielsen_indexes.csv',nrows=5000000,index_col=0)\n",
    "df_test.to_csv(DATA_PATH+'/nielsen_indexes_light.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def aggregate(chunk):\n",
    "    \n",
    "    chunk['count']=1\n",
    "    groupy = chunk.groupby(['id_devices','id_sites']).count()\n",
    "    groupy = groupy.reset_index()\n",
    "    \n",
    "    groupy =groupy.groupby('id_devices')['id_sites'].apply(lambda x: x.tolist())\n",
    "    return pd.DataFrame(groupy)\n",
    "\n",
    "def aggregate_per_devices_and_sites():\n",
    "    chunks = pd.read_csv(DATA_PATH+'/nielsen_indexes.csv',chunksize=40000000,index_col=0)\n",
    "    df =pd.DataFrame()\n",
    "    \n",
    "    for i,chunk in enumerate(chunks):\n",
    "        df = pd.concat([df,aggregate(chunk)], axis=1, ignore_index=False)\n",
    "        df = df.fillna(0)\n",
    "        \n",
    "        print df.shape,i\n",
    "    df.to_csv(DATA_PATH+'/nielsen_indexes_pivot.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 4- Clean data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def combine_sites_id(df):\n",
    "    cols = df.columns.tolist()\n",
    "    df = df.replace('0', 0)\n",
    "    df =df.replace(0,\"\")\n",
    "    df = df.fillna(\"\")\n",
    "    df['sites_id']= df[cols].astype(str).sum(axis=1)\n",
    "    df['sites_id_array']= df['sites_id'].apply(pdh.string_to_np_array)\n",
    "    df['sites_count']= df['sites_id_array'].apply(lambda x: x.size)\n",
    "    df = df[['sites_id_array','sites_count']]\n",
    "    df.reset_index()\n",
    "    return df\n",
    "    \n",
    "    \n",
    "def clean_data():\n",
    "    chunks = pd.read_csv(DATA_PATH+'nielsen_indexes_pivot.csv',chunksize=1000000,index_col=0)\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    for i,chunk in enumerate(chunks):\n",
    "        df = pd.concat([df,combine_sites_id(chunk)],axis=0)\n",
    "        print df.shape,i\n",
    "    print \"Combining done, saving to file...\"\n",
    "    df.to_csv(DATA_PATH+\"nielsen_indexes_sites_per_devices.csv\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000000, 2) 0\n",
      "(2000000, 2) 1\n",
      "(3000000, 2) 2\n",
      "(4000000, 2) 3\n",
      "(5000000, 2) 4\n",
      "(6000000, 2) 5\n",
      "(7000000, 2) 6\n",
      "(8000000, 2) 7\n",
      "(9000000, 2) 8\n",
      "(10000000, 2) 9\n",
      "(11000000, 2) 10\n",
      "(12000000, 2) 11\n",
      "(13000000, 2) 12\n",
      "(14000000, 2) 13\n",
      "(15000000, 2) 14\n",
      "(16000000, 2) 15\n",
      "(17000000, 2) 16\n",
      "(18000000, 2) 17\n",
      "(19000000, 2) 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ramon/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2885: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000000, 2) 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ramon/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2885: DtypeWarning: Columns (2,3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21000000, 2) 20\n",
      "(21010205, 2) 21\n"
     ]
    }
   ],
   "source": [
    "clean_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
